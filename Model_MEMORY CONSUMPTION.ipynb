{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab82f6c",
   "metadata": {},
   "source": [
    "# nous-hermes-llama2-13b (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231b9907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gpt4all pdfminer.six psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a044b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 6944.6953 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.3477 MB\n",
      "Memory usage for input 'Describe the princip...': -708.5625 MB\n",
      "Average memory usage for Nous-Hermes-Llama2-13b.Q4_0.gguf: 2078.8268 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text.split('\\n')\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "   \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the PDF dataset file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Extract the dataset\n",
    "    test_inputs = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Filter out short or irrelevant lines\n",
    "    test_inputs = [line for line in test_inputs if len(line) > 10]\n",
    "    \n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for Nous-Hermes-Llama2-13b.Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db3277",
   "metadata": {},
   "source": [
    "# nous-hermes-llama2-13b (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a59d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 6906.4961 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.2852 MB\n",
      "Memory usage for input 'Describe the princip...': 0.4609 MB\n",
      "Average memory usage for Nous-Hermes-Llama2-13b.Q4_0.gguf: 2302.4141 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Complex prompts\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for Nous-Hermes-Llama2-13b.Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22236509",
   "metadata": {},
   "source": [
    "# gpt4all-13b-snoozy-Q4_0 (with just PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb2f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 6918.0742 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.5234 MB\n",
      "Memory usage for input 'Describe the princip...': 0.4570 MB\n",
      "Average memory usage for gpt4all-13b-snoozy-Q4_0.gguf: 2306.3516 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text.split('\\n')\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "   \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the PDF dataset file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Extract the dataset\n",
    "    test_inputs = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Filter out short or irrelevant lines\n",
    "    test_inputs = [line for line in test_inputs if len(line) > 10]\n",
    "    \n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for gpt4all-13b-snoozy-Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5bb3c",
   "metadata": {},
   "source": [
    "# gpt4all-13b-snoozy-Q4_0 (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a468c001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 6940.6094 MB\n",
      "Memory usage for input 'Discuss the scope of...': -5.7344 MB\n",
      "Memory usage for input 'Describe the princip...': -702.3750 MB\n",
      "Average memory usage for gpt4all-13b-snoozy-Q4_0.gguf: 2077.5000 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Complex prompts\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for gpt4all-13b-snoozy-Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f839b80",
   "metadata": {},
   "source": [
    "# mistral-7b-openorca (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c65ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 3851.3047 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.0742 MB\n",
      "Memory usage for input 'Describe the princip...': 0.0938 MB\n",
      "Average memory usage for mistral-7b-openorca.gguf2.Q4_0.gguf: 1283.8242 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text.split('\\n')\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "   \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the PDF dataset file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Extract the dataset\n",
    "    test_inputs = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Filter out short or irrelevant lines\n",
    "    test_inputs = [line for line in test_inputs if len(line) > 10]\n",
    "    \n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for mistral-7b-openorca.gguf2.Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639a5f",
   "metadata": {},
   "source": [
    "# mistral-7b-openorca (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ee2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 3851.3359 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.0742 MB\n",
      "Memory usage for input 'Describe the princip...': 0.0977 MB\n",
      "Average memory usage for mistral-7b-openorca.gguf2.Q4_0.gguf: 1283.8359 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Complex prompts\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for mistral-7b-openorca.gguf2.Q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5212ab9",
   "metadata": {},
   "source": [
    "# gpt4all-falcon-newbpe (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553ada18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 3840.9062 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.5039 MB\n",
      "Memory usage for input 'Describe the princip...': 0.3711 MB\n",
      "Average memory usage for gpt4all-falcon-newbpe-q4_0.gguf: 1280.5938 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text.split('\\n')\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "   \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the PDF dataset file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Extract the dataset\n",
    "    test_inputs = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Filter out short or irrelevant lines\n",
    "    test_inputs = [line for line in test_inputs if len(line) > 10]\n",
    "    \n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for gpt4all-falcon-newbpe-q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe86d7",
   "metadata": {},
   "source": [
    "# gpt4all-falcon-newbpe (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35a3f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\priyank\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf...\n",
      "Model loaded.\n",
      "Memory usage for input 'Explain the purpose ...': 3860.7031 MB\n",
      "Memory usage for input 'Discuss the scope of...': 0.3711 MB\n",
      "Memory usage for input 'Describe the princip...': 0.1953 MB\n",
      "Average memory usage for gpt4all-falcon-newbpe-q4_0.gguf: 1287.0898 MB\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all psutil\n",
    "\n",
    "# Import required libraries\n",
    "import psutil\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure memory consumption\n",
    "def infer_memory_usage(model, input_text):\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB before inference\n",
    "    response = model.generate(input_text)\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)  # Memory usage in MB after inference\n",
    "    memory_usage = mem_after - mem_before\n",
    "    print(f\"Memory usage for input '{input_text[:20]}...': {memory_usage:.4f} MB\")\n",
    "    return memory_usage\n",
    "\n",
    "# Complex prompts\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure memory consumption for each complex prompt\n",
    "    memory_usages = [infer_memory_usage(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average memory usage\n",
    "    average_memory_usage = sum(memory_usages) / len(memory_usages)\n",
    "    print(f\"Average memory usage for gpt4all-falcon-newbpe-q4_0.gguf: {average_memory_usage:.4f} MB\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179f987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
