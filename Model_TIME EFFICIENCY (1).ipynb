{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ddc67a",
   "metadata": {},
   "source": [
    "# nous-hermes (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a22855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gpt4all pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f53a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 149.8371 seconds\n",
      "Inference time for input 'Discuss the scope of...': 146.9645 seconds\n",
      "Inference time for input 'Describe the princip...': 150.3610 seconds\n",
      "Average inference time for nous-hermes-llama2-13b.Q4_0.gguf: 149.0542 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six\n",
    "\n",
    "# Import required libraries\n",
    "import time\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return inference_time\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure time efficiency for each complex prompt\n",
    "    inference_times = [infer(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for nous-hermes-llama2-13b.Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da2202",
   "metadata": {},
   "source": [
    "# nous-hermes (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23136e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)Loading model from C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf...\n",
      "\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\priyank\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from Levenshtein) (3.9.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 126.7757 seconds\n",
      "Inference time for input 'Discuss the scope of...': 102.7743 seconds\n",
      "Inference time for input 'Describe the princip...': 116.8028 seconds\n",
      "Average inference time for Nous-Hermes-Llama2-13b.Q4_0.gguf: 115.4509 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six Levenshtein\n",
    "\n",
    "# Importing the libraries which are required\n",
    "import time\n",
    "import Levenshtein\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return response, inference_time\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "# Main function to run\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\nous-hermes-llama2-13b.Q4_0.gguf'\n",
    "    # Path to the PDF file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Loading the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Prompts which are based on the test PDF file\n",
    "    complex_prompts = [\n",
    "        \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "        \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "        \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    ]\n",
    "    \n",
    "    # Measuring the time efficiency for each complex prompt\n",
    "    inference_times = []\n",
    "    for prompt in complex_prompts:\n",
    "        response, inference_time = infer(model, prompt)\n",
    "        inference_times.append(inference_time)\n",
    "    \n",
    "    # Calculating the average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for Nous-Hermes-Llama2-13b.Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Executing the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e449e17",
   "metadata": {},
   "source": [
    "# gpt4all-13b-snoozy (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0432ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 137.7567 seconds\n",
      "Inference time for input 'Discuss the scope of...': 118.2463 seconds\n",
      "Inference time for input 'Describe the princip...': 118.9502 seconds\n",
      "Average inference time for gpt4all-13b-snoozy-Q4_0.gguf: 124.9844 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six\n",
    "\n",
    "# Import required libraries\n",
    "import time\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return inference_time\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure time efficiency for each complex prompt\n",
    "    inference_times = [infer(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for gpt4all-13b-snoozy-Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ac6",
   "metadata": {},
   "source": [
    "# gpt4all-13b-snoozy (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0e8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\priyank\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from Levenshtein) (3.9.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 120.5451 seconds\n",
      "Inference time for input 'Discuss the scope of...': 117.9724 seconds\n",
      "Inference time for input 'Describe the princip...': 120.2035 seconds\n",
      "Average inference time for gpt4all-13b-snoozy-Q4_0.gguf: 119.5737 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six Levenshtein\n",
    "\n",
    "# Importing the libraries which are required\n",
    "import time\n",
    "import Levenshtein\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return response, inference_time\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "# Main function to run\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-13b-snoozy-Q4_0.gguf'\n",
    "    # Path to the PDF file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Loading the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Prompts which are based on the test PDF file\n",
    "    complex_prompts = [\n",
    "        \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "        \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "        \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    ]\n",
    "    \n",
    "    # Measuring the time efficiency for each complex prompt\n",
    "    inference_times = []\n",
    "    for prompt in complex_prompts:\n",
    "        response, inference_time = infer(model, prompt)\n",
    "        inference_times.append(inference_time)\n",
    "    \n",
    "    # Calculating the average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for gpt4all-13b-snoozy-Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Executing the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598daa6c",
   "metadata": {},
   "source": [
    "# mistral-7b-openorca (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d0d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 20.3384 seconds\n",
      "Inference time for input 'Discuss the scope of...': 8.3902 seconds\n",
      "Inference time for input 'Describe the princip...': 8.6588 seconds\n",
      "Average inference time for mistral-7b-openorca.gguf2.Q4_0.gguf: 12.4625 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six\n",
    "\n",
    "# Import required libraries\n",
    "import time\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return inference_time\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure time efficiency for each complex prompt\n",
    "    inference_times = [infer(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for mistral-7b-openorca.gguf2.Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c834d0",
   "metadata": {},
   "source": [
    "# mistral-7b-openorca (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ed422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)Loading model from C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf...\n",
      "\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\priyank\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from Levenshtein) (3.9.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 10.1479 seconds\n",
      "Inference time for input 'Discuss the scope of...': 8.5242 seconds\n",
      "Inference time for input 'Describe the princip...': 8.6150 seconds\n",
      "Average inference time for mistral-7b-openorca.gguf2.Q4_0.gguf: 9.0957 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six Levenshtein\n",
    "\n",
    "# Importing the libraries which are required\n",
    "import time\n",
    "import Levenshtein\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return response, inference_time\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "# Main function to run\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\mistral-7b-openorca.gguf2.Q4_0.gguf'\n",
    "    # Path to the PDF file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Loading the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Prompts which are based on the test PDF file\n",
    "    complex_prompts = [\n",
    "        \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "        \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "        \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    ]\n",
    "    \n",
    "    # Measuring the time efficiency for each complex prompt\n",
    "    inference_times = []\n",
    "    for prompt in complex_prompts:\n",
    "        response, inference_time = infer(model, prompt)\n",
    "        inference_times.append(inference_time)\n",
    "    \n",
    "    # Calculating the average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for mistral-7b-openorca.gguf2.Q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Executing the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d143e",
   "metadata": {},
   "source": [
    "# gpt4all-falcon-newbpe (with just prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f05f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 72.5124 seconds\n",
      "Inference time for input 'Discuss the scope of...': 63.5614 seconds\n",
      "Inference time for input 'Describe the princip...': 62.5283 seconds\n",
      "Average inference time for gpt4all-falcon-newbpe-q4_0.gguf: 66.2007 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six\n",
    "\n",
    "# Import required libraries\n",
    "import time\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return inference_time\n",
    "\n",
    "# Complex prompts based on the PDF content\n",
    "complex_prompts = [\n",
    "    \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "    \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "    \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Main function to execute the benchmarking\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf'  # Ensure this path is correct\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Measure time efficiency for each complex prompt\n",
    "    inference_times = [infer(model, prompt) for prompt in complex_prompts]\n",
    "    \n",
    "    # Calculate average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for gpt4all-falcon-newbpe-q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3cc183",
   "metadata": {},
   "source": [
    "# gpt4all-falcon-newbpe (with given PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62a3b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt4all in c:\\users\\priyank\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\priyank\\anaconda3\\lib\\site-packages (20231228)\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\priyank\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from Levenshtein) (3.9.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\priyank\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Loading model from C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf...\n",
      "Model loaded.\n",
      "Inference time for input 'Explain the purpose ...': 62.8141 seconds\n",
      "Inference time for input 'Discuss the scope of...': 62.3117 seconds\n",
      "Inference time for input 'Describe the princip...': 62.9707 seconds\n",
      "Average inference time for gpt4all-falcon-newbpe-q4_0.gguf: 62.6988 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install gpt4all pdfminer.six Levenshtein\n",
    "\n",
    "# Importing the libraries which are required\n",
    "import time\n",
    "import Levenshtein\n",
    "from gpt4all import GPT4All\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = GPT4All(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Function to perform inference and measure time\n",
    "def infer(model, input_text):\n",
    "    start_time = time.time()\n",
    "    response = model.generate(input_text)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(f\"Inference time for input '{input_text[:20]}...': {inference_time:.4f} seconds\")\n",
    "    return response, inference_time\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "# Main function to run\n",
    "def main():\n",
    "    # Path to the local model file\n",
    "    model_path = r'C:\\Users\\Priyank\\Downloads\\gpt4all-falcon-newbpe-q4_0.gguf'\n",
    "    # Path to the PDF file\n",
    "    pdf_path = r'C:\\Users\\Priyank\\Downloads\\test.pdf'\n",
    "    \n",
    "    # Loading the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Prompts which are based on the test PDF file\n",
    "    complex_prompts = [\n",
    "        \"Explain the purpose of the Research Integrity Policy at Flinders University and how it aligns with the Australian Code for the Responsible Conduct of Research.\",\n",
    "        \"Discuss the scope of the Research Integrity Policy at Flinders University, including who it applies to and the types of research activities it covers.\",\n",
    "        \"Describe the principles and responsibilities outlined in the Research Integrity Policy for researchers at Flinders University. How do these principles ensure responsible research conduct?\"\n",
    "    ]\n",
    "    \n",
    "    # Measuring the time efficiency for each complex prompt\n",
    "    inference_times = []\n",
    "    for prompt in complex_prompts:\n",
    "        response, inference_time = infer(model, prompt)\n",
    "        inference_times.append(inference_time)\n",
    "    \n",
    "    # Calculating the average inference time\n",
    "    average_time = sum(inference_times) / len(inference_times)\n",
    "    print(f\"Average inference time for gpt4all-falcon-newbpe-q4_0.gguf: {average_time:.4f} seconds\")\n",
    "\n",
    "# Executing the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ac73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
